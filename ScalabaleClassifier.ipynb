{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScalabaleClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9gDnTaLBQfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import pandas as pd \n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob4bYi0XDgP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of layers in the network\n",
        "NUM_LAYERS = 2\n",
        "# Nimber of features of the input data\n",
        "FEATURES_NUM_X = 7\n",
        "# Number of classes to classify\n",
        "CLASSES_NUMBER = 2\n",
        "# Mini batch size\n",
        "MINI_BATCH_SIZE = 32\n",
        "\n",
        "# layers is a vector with the length corrisponding to the number of layers we want\n",
        "# in the network and the scalar at each position represents the number of neurons\n",
        "layers = [8, CLASSES_NUMBER]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGIYmb4optBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_data(data):\n",
        "    \"\"\" \n",
        "    Map the string values in the dataset\n",
        "    \n",
        "    Arguments:\n",
        "    data: panda dataset\n",
        "\n",
        "    Returns:\n",
        "    data: panda dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # Map every string in the dataset, we can only have numbers\n",
        "    sex_class_mapping = {label: idx for idx, label in enumerate(np.unique(data[\"Sex\"]))}\n",
        "    # The final astype ensures the object is treated like a string\n",
        "    embarked_class_mapping = {label: idx for idx, label in enumerate(np.unique(data[\"Embarked\"].astype(str)))}\n",
        "    data[\"Sex\"] = data[\"Sex\"].map(sex_class_mapping)\n",
        "    data[\"Embarked\"] = data[\"Embarked\"].map(embarked_class_mapping)\n",
        "    data['Fare'] = data['Fare'].astype(int)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ztx1tV6aroN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(X, y, test_size=0.2, random_state=0):\n",
        "  \"\"\" \n",
        "  Split arrays or matrices into random train and test subsets\n",
        "    \n",
        "  Arguments:\n",
        "  X: panda feature dataset\n",
        "  y: panda feature dataset\n",
        "  test_size: size of the returning test set\n",
        "  random_state: random seed to shuffle data \n",
        "\n",
        "  Returns:\n",
        "  X_train: train subset of the original dataset\n",
        "  y_train: train label subset of the original dataset\n",
        "  X_test: test subset of the original dataset\n",
        "  y_train: test label subset of the original dataset\n",
        "  \"\"\"\n",
        "  X, y = shuffle(X, y, random_state= random_state)\n",
        "  part_to_take = int(len(X) * 0.2)\n",
        "\n",
        "  X_train = X.head(len(X) - part_to_take)\n",
        "  Y_train = y.head(len(X) - part_to_take)\n",
        "  X_test = X.tail(part_to_take)\n",
        "  Y_test = y.tail(part_to_take)\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5mstNcUlmXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def manage_nan_values(data):\n",
        "  \"\"\" \n",
        "  Replace the NaN values of the dataset with the mean of the column\n",
        "    \n",
        "  Arguments:\n",
        "  data: panda dataset\n",
        "\n",
        "  Returns:\n",
        "  data: panda dataset\n",
        "  \"\"\"\n",
        "    return data.where(pd.notna(data), data.mean(), axis='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcS_uXCSPYzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_batches(X, y, batch_size, random_state = 0):\n",
        "  \"\"\" \n",
        "  Split dataset in mini batches\n",
        "    \n",
        "  Arguments:\n",
        "  X: panda feature dataset\n",
        "  y: panda feature dataset\n",
        "  batch_size: size of each batch\n",
        "  random_state: random seed to shuffle data \n",
        "\n",
        "  Returns:\n",
        "  mini_batches: array of tuples containing (mini_x, mini_y)\n",
        "  \"\"\"\n",
        "  X, y = shuffle(X, y, random_state=random_state)\n",
        "  num_of_batches = int(len(X) / batch_size)\n",
        "  dec_part = len(X) % batch_size\n",
        "  mini_batches = [] \n",
        "\n",
        "  for i in range(0, num_of_batches):\n",
        "    from_index = i*batch_size\n",
        "    to_index = from_index+batch_size\n",
        "    mini_batches.append((X.iloc[from_index:to_index], y.iloc[from_index:to_index]))\n",
        "\n",
        "  mini_batches.append((X.iloc[batch_size*num_of_batches:], y.iloc[batch_size*num_of_batches:]))\n",
        "\n",
        "  return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7RJPEA1GYJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def one_hot_encoding(indices):\n",
        "  \"\"\" \n",
        "  One hot encoding of the label dataset\n",
        "    \n",
        "  Arguments:\n",
        "  indices: panda label dataset\n",
        "\n",
        "  Returns:\n",
        "  one hot encoding of the input dataset\n",
        "  \"\"\"\n",
        "\n",
        "  return pd.get_dummies(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "083YzYmpBkfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(x_size, y_size):\n",
        "\n",
        "    \"\"\" \n",
        "    Create the placeholders for the session\n",
        "    \n",
        "    Arguments:\n",
        "    x_size: number of features of the input data\n",
        "    y_size: number of classes of labels\n",
        "\n",
        "    Returns:\n",
        "    X: placeholder for the input data\n",
        "    Y: placeholder for the output data\n",
        "    \"\"\"\n",
        "\n",
        "    X = tf.placeholder(tf.float32, [x_size, None], name=\"X\")\n",
        "    Y = tf.placeholder(tf.float32, [y_size, None], name=\"Y\")\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkLFYjGoBwaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        "    \n",
        "    \"\"\" \n",
        "    Initialize the params for the network\n",
        "    \n",
        "    Arguments: --\n",
        "\n",
        "    Returns:\n",
        "    parameters: a key value object that stores the weights and the bias\n",
        "     \"\"\"\n",
        "\n",
        "    parameters = {}\n",
        "    for i in range(0, NUM_LAYERS):\n",
        "      if i==0:\n",
        "        parameters[\"W1\"] = tf.get_variable(\"W1\", [layers[i], FEATURES_NUM_X], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "      else:\n",
        "        parameters[\"W\"+str(i+1)] = tf.get_variable(\"W\"+str(i+1), [layers[i], layers[i-1]], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "      parameters[\"b\"+str(i+1)] = tf.get_variable(\"b\"+str(i+1), [layers[i], 1], initializer = tf.zeros_initializer())\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8jVkNcIz_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "\n",
        "    \"\"\" \n",
        "    Implements forward propagation, it uses the same activation function for the whole network\n",
        "    \n",
        "    Arguments: \n",
        "    X: input data\n",
        "    parameters: key value object containing weigths and params\n",
        "\n",
        "    Returns:\n",
        "    Z[\"Z\" + (NUM_LAYERS)]: last computed weight computation\n",
        "     \"\"\"\n",
        "\n",
        "    Z = {}\n",
        "    A = {}\n",
        "\n",
        "    A[\"A0\"] = X\n",
        "    for i in range(0, NUM_LAYERS):\n",
        "      Z[\"Z\"+ str(i+1)] = tf.add(tf.matmul(parameters[\"W\"+str(i+1)], A[\"A\"+str(i)]), parameters[\"b\"+ str(i+1)])\n",
        "      if (i+1) != NUM_LAYERS:\n",
        "        A[\"A\"+ str(i+1)] = tf.nn.relu(Z[\"Z\"+ str(i+1)])\n",
        "    \n",
        "    return Z[\"Z\" + str(NUM_LAYERS)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ21l38UK4td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(least_z, Y):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "    \n",
        "    Arguments:\n",
        "    least_z: least computed z of the network\n",
        "    Y -- ground truth\n",
        "    \n",
        "    Returns:\n",
        "    cost: tensor of the cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    logits = tf.transpose(least_z)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-yTRM11LSyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          num_epochs = 1000, minibatch_size = 32, print_cost = True):\n",
        "    \n",
        "    ops.reset_default_graph()       \n",
        "    m = X_train.shape[0]\n",
        "    n_y = CLASSES_NUMBER\n",
        "    costs = []\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    X, Y = create_placeholders(FEATURES_NUM_X, CLASSES_NUMBER)\n",
        "\n",
        "    # Initialize parameters\n",
        "    parameters = initialize_parameters()\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    least_z = forward_propagation(X, parameters)\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    cost = compute_cost(least_z, Y)\n",
        "    \n",
        "    # Backpropagation\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_cost = 0.\n",
        "            num_minibatches = int(m / minibatch_size)\n",
        "            minibatches = split_batches(X_train, Y_train, minibatch_size, epoch)\n",
        "\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X.T, Y: minibatch_Y.T})\n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            if print_cost == True:\n",
        "              if epoch % 100 == 0:\n",
        "                  print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "              if epoch % 5 == 0:\n",
        "                  costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per fives)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(least_z), tf.argmax(Y))\n",
        "          \n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "   \n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train.T, Y: y_train.T}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test.T, Y: y_test.T}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTVh3iEHSciH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"data/train.csv\") \n",
        "\n",
        "y = data.Survived\n",
        "X = data.drop([\"Survived\", \"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"], axis=1)\n",
        "X = map_data(X)\n",
        "X = manage_nan_values(X)\n",
        "\n",
        "y = one_hot_encoding(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.03)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMWDmDOmXQTD",
        "colab_type": "code",
        "outputId": "e4dd6585-dec9-42b4-87bf-1f9bd304d706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "parameters = model(X_train, y_train, X_test, y_test, learning_rate = 0.001, minibatch_size=MINI_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.267201\n",
            "Cost after epoch 100: 0.466646\n",
            "Cost after epoch 200: 0.449542\n",
            "Cost after epoch 300: 0.443506\n",
            "Cost after epoch 400: 0.443924\n",
            "Cost after epoch 500: 0.445774\n",
            "Cost after epoch 600: 0.428326\n",
            "Cost after epoch 700: 0.427163\n",
            "Cost after epoch 800: 0.434086\n",
            "Cost after epoch 900: 0.428610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhGRgPt/HJW59pEIcN4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.8134642\n",
            "Test Accuracy: 0.78651685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CifKCU1Hr5Bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}